{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 手写数字的数据集MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source：** part2_mnist_data_set.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# working with the MNIST data set\n",
    "#\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the CSV file and read its contents into a list\n",
    "data_file = open(\"mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of data records (examples)\n",
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a dataset record\n",
    "# the first number is the label, the rest are pixel colour values (greyscale 0-255)\n",
    "data_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，第一个数字5是标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19e47315730>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take the data from a record, rearrange it into a 28*28 array and plot it as an image\n",
    "# 把784个数转换为28*28的数组\n",
    "all_values = data_list[10].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "# 灰度调色板\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.1 准备MNIST训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.17305882 0.46811765 0.86023529\n",
      " 0.65447059 0.46811765 0.46811765 0.03329412 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.40988235 0.94952941 0.99611765 0.99611765 0.99611765 0.99611765\n",
      " 0.99611765 0.26623529 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.07988235 0.91070588\n",
      " 0.99611765 0.99611765 0.99611765 0.99611765 0.99611765 0.934\n",
      " 0.28176471 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.41376471 0.95729412 0.99611765\n",
      " 0.87964706 0.99611765 0.99611765 0.99611765 0.55741176 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.81364706 0.99611765 0.82529412 0.99611765\n",
      " 0.99611765 0.99611765 0.142      0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.33611765 0.80976471 0.99611765 0.99611765 0.99611765 0.99611765\n",
      " 0.16917647 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.10317647\n",
      " 0.82141176 0.99611765 0.99611765 0.99611765 0.67388235 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.36329412 0.54188235 0.99223529 0.99611765\n",
      " 0.99611765 0.99611765 0.44482353 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.16529412 0.84082353\n",
      " 0.98058824 0.99611765 0.99611765 0.99611765 0.99611765 0.99611765\n",
      " 0.142      0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.32447059 0.96894118 0.99611765 0.99611765\n",
      " 0.99611765 0.99611765 0.99611765 0.99611765 0.57682353 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.43705882 0.96505882 0.99611765 0.99611765 0.99611765\n",
      " 0.99611765 0.99611765 0.67388235 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.29341176 0.35552941 0.35552941 0.37105882 0.94176471 0.99611765\n",
      " 0.67388235 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01388235 0.50694118 0.99611765 0.86023529 0.13035294\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.03717647\n",
      " 0.99611765 0.99611765 0.84082353 0.11870588 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.54576471 0.99611765 0.99611765\n",
      " 0.46035294 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.08376471 0.69717647\n",
      " 0.35941176 0.01       0.01       0.01       0.01       0.01\n",
      " 0.10705882 0.94176471 0.99611765 0.99611765 0.142      0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.64670588 0.99611765 0.84470588 0.25458824\n",
      " 0.14976471 0.01       0.208      0.35552941 0.80976471 0.99611765\n",
      " 0.99611765 0.54964706 0.04105882 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.23129412 0.77482353 0.99611765 0.99611765 0.87188235 0.70882353\n",
      " 0.94564706 0.99611765 0.99611765 0.99223529 0.83694118 0.05270588\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.55352941\n",
      " 0.41764706 0.99611765 0.99611765 0.99611765 0.99611765 0.99611765\n",
      " 0.99611765 0.92623529 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.03717647 0.46423529\n",
      " 0.46423529 0.65058824 0.99611765 0.99611765 0.93788235 0.20411765\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01      ]\n"
     ]
    }
   ],
   "source": [
    "# scale input to range 0.01 to 1.00\n",
    "scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output nodes is 10 (example)\n",
    "onodes = 10\n",
    "targets = numpy.zeros(onodes) + 0.01\n",
    "targets[int(all_values[0])] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source：** part2_neural_network_mnist_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "# 训练数据循环5遍\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "\n",
    "        # 训练神经网络n\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.2 测试网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test_10.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试一下test_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19e47533cd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take the data from a record, rearrange it into a 28*28 array and plot it as an image\n",
    "# 把784个数转换为28*28的数组\n",
    "all_values = test_data_list[0].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "# 灰度调色板\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03947367],\n",
       "       [0.00422177],\n",
       "       [0.05013139],\n",
       "       [0.01939337],\n",
       "       [0.01086232],\n",
       "       [0.04890035],\n",
       "       [0.00135184],\n",
       "       [0.92798919],\n",
       "       [0.01571626],\n",
       "       [0.03259313]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第7个为最大值[0.92798919], Bingo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 correct_label\n",
      "7 network's answer\n",
      "2 correct_label\n",
      "2 network's answer\n",
      "1 correct_label\n",
      "1 network's answer\n",
      "0 correct_label\n",
      "0 network's answer\n",
      "4 correct_label\n",
      "4 network's answer\n",
      "1 correct_label\n",
      "1 network's answer\n",
      "4 correct_label\n",
      "9 network's answer\n",
      "9 correct_label\n",
      "4 network's answer\n",
      "5 correct_label\n",
      "4 network's answer\n",
      "9 correct_label\n",
      "9 network's answer\n"
     ]
    }
   ],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    print(correct_label, \"correct_label\")\n",
    "\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    print(label, \"network's answer\")\n",
    "\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一共预测对了6个！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(scorecard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.7\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print(\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5.3 使用完整数据集进行训练和测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source：** part2_neural_network_mnist_data.ipynb\n",
    "\n",
    "代码同上一节，但使用完整数据集。\n",
    "\n",
    "但完整数据集太大了，没有下载，所以代码不能运行\n",
    "\n",
    "准确率0.9712，还是非常高的！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
